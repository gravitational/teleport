// Copyright 2025 Gravitational, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: teleport/summarizer/v1/summarizer.proto

package summarizerv1

import (
	v1 "github.com/gravitational/teleport/api/gen/proto/go/teleport/header/v1"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	structpb "google.golang.org/protobuf/types/known/structpb"
	timestamppb "google.golang.org/protobuf/types/known/timestamppb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// SummaryState is the state of the summarization process.
type SummaryState int32

const (
	SummaryState_SUMMARY_STATE_UNSPECIFIED SummaryState = 0
	SummaryState_SUMMARY_STATE_PENDING     SummaryState = 1
	SummaryState_SUMMARY_STATE_SUCCESS     SummaryState = 2
	SummaryState_SUMMARY_STATE_ERROR       SummaryState = 3
)

// Enum value maps for SummaryState.
var (
	SummaryState_name = map[int32]string{
		0: "SUMMARY_STATE_UNSPECIFIED",
		1: "SUMMARY_STATE_PENDING",
		2: "SUMMARY_STATE_SUCCESS",
		3: "SUMMARY_STATE_ERROR",
	}
	SummaryState_value = map[string]int32{
		"SUMMARY_STATE_UNSPECIFIED": 0,
		"SUMMARY_STATE_PENDING":     1,
		"SUMMARY_STATE_SUCCESS":     2,
		"SUMMARY_STATE_ERROR":       3,
	}
)

func (x SummaryState) Enum() *SummaryState {
	p := new(SummaryState)
	*p = x
	return p
}

func (x SummaryState) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (SummaryState) Descriptor() protoreflect.EnumDescriptor {
	return file_teleport_summarizer_v1_summarizer_proto_enumTypes[0].Descriptor()
}

func (SummaryState) Type() protoreflect.EnumType {
	return &file_teleport_summarizer_v1_summarizer_proto_enumTypes[0]
}

func (x SummaryState) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use SummaryState.Descriptor instead.
func (SummaryState) EnumDescriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{0}
}

// InferenceModel resource specifies a session summarization inference model
// configuration. It tells Teleport how to use a specific provider and model to
// summarize sessions.
type InferenceModel struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Kind is the resource kind. Should always be set to "inference_model".
	Kind string `protobuf:"bytes,1,opt,name=kind,proto3" json:"kind,omitempty"`
	// SubKind is the resource sub-kind. Should be empty.
	SubKind string `protobuf:"bytes,2,opt,name=sub_kind,json=subKind,proto3" json:"sub_kind,omitempty"`
	// Version is the resource version. Should be set to "v1".
	Version       string              `protobuf:"bytes,3,opt,name=version,proto3" json:"version,omitempty"`
	Metadata      *v1.Metadata        `protobuf:"bytes,4,opt,name=metadata,proto3" json:"metadata,omitempty"`
	Spec          *InferenceModelSpec `protobuf:"bytes,5,opt,name=spec,proto3" json:"spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceModel) Reset() {
	*x = InferenceModel{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceModel) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceModel) ProtoMessage() {}

func (x *InferenceModel) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceModel.ProtoReflect.Descriptor instead.
func (*InferenceModel) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{0}
}

func (x *InferenceModel) GetKind() string {
	if x != nil {
		return x.Kind
	}
	return ""
}

func (x *InferenceModel) GetSubKind() string {
	if x != nil {
		return x.SubKind
	}
	return ""
}

func (x *InferenceModel) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *InferenceModel) GetMetadata() *v1.Metadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferenceModel) GetSpec() *InferenceModelSpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

// InferenceModelSpec specifies the inference provider and provider-specific
// parameters.
type InferenceModelSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Provider:
	//
	//	*InferenceModelSpec_Openai
	Provider      isInferenceModelSpec_Provider `protobuf_oneof:"provider"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceModelSpec) Reset() {
	*x = InferenceModelSpec{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceModelSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceModelSpec) ProtoMessage() {}

func (x *InferenceModelSpec) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceModelSpec.ProtoReflect.Descriptor instead.
func (*InferenceModelSpec) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{1}
}

func (x *InferenceModelSpec) GetProvider() isInferenceModelSpec_Provider {
	if x != nil {
		return x.Provider
	}
	return nil
}

func (x *InferenceModelSpec) GetOpenai() *OpenAIProvider {
	if x != nil {
		if x, ok := x.Provider.(*InferenceModelSpec_Openai); ok {
			return x.Openai
		}
	}
	return nil
}

type isInferenceModelSpec_Provider interface {
	isInferenceModelSpec_Provider()
}

type InferenceModelSpec_Openai struct {
	// Openai indicates that this model uses OpenAI as the inference provider
	// and specifies OpenAI-specific parameters.
	Openai *OpenAIProvider `protobuf:"bytes,1,opt,name=openai,proto3,oneof"`
}

func (*InferenceModelSpec_Openai) isInferenceModelSpec_Provider() {}

// OpenAIProvider specifies OpenAI-specific parameters. It can be used to
// configure OpenAI or an OpenAI-compatible API, such as LiteLLM.
type OpenAIProvider struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// OpenaiModelId specifies the model ID, as understood by the OpenAI API.
	OpenaiModelId string `protobuf:"bytes,1,opt,name=openai_model_id,json=openaiModelId,proto3" json:"openai_model_id,omitempty"`
	// Temperature controls the randomness of the model's output.
	Temperature float64 `protobuf:"fixed64,2,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// ApiKeySecretRef is a reference to an InferenceSecret that contains the
	// OpenAI API key.
	ApiKeySecretRef string `protobuf:"bytes,3,opt,name=api_key_secret_ref,json=apiKeySecretRef,proto3" json:"api_key_secret_ref,omitempty"`
	// BaseUrl is the OpenAI API base URL. Optional, defaults to the public
	// OpenAI API URL. May be used to point to a custom OpenAI-compatible API,
	// such as LiteLLM. In such case, the `api_key_secret_ref` must point to a
	// secret that contains the API key for that custom API.
	BaseUrl       string `protobuf:"bytes,4,opt,name=base_url,json=baseUrl,proto3" json:"base_url,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *OpenAIProvider) Reset() {
	*x = OpenAIProvider{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *OpenAIProvider) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*OpenAIProvider) ProtoMessage() {}

func (x *OpenAIProvider) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use OpenAIProvider.ProtoReflect.Descriptor instead.
func (*OpenAIProvider) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{2}
}

func (x *OpenAIProvider) GetOpenaiModelId() string {
	if x != nil {
		return x.OpenaiModelId
	}
	return ""
}

func (x *OpenAIProvider) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *OpenAIProvider) GetApiKeySecretRef() string {
	if x != nil {
		return x.ApiKeySecretRef
	}
	return ""
}

func (x *OpenAIProvider) GetBaseUrl() string {
	if x != nil {
		return x.BaseUrl
	}
	return ""
}

// InferenceSecret resource stores session summarization inference provider
// secrets, such as API keys. They need to be referenced by appropriate
// provider configuration inside `InferenceModelSpec`.
type InferenceSecret struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Kind is the resource kind. Should always be set to "inference_secret".
	Kind string `protobuf:"bytes,1,opt,name=kind,proto3" json:"kind,omitempty"`
	// SubKind is the resource sub-kind. Should be empty.
	SubKind string `protobuf:"bytes,2,opt,name=sub_kind,json=subKind,proto3" json:"sub_kind,omitempty"`
	// Version is the resource version. Should be set to "v1".
	Version  string       `protobuf:"bytes,3,opt,name=version,proto3" json:"version,omitempty"`
	Metadata *v1.Metadata `protobuf:"bytes,4,opt,name=metadata,proto3" json:"metadata,omitempty"`
	// Spec contains the secret value. Once set, it can only be read by Teleport
	// itself; it will not be returned in API responses.
	Spec          *InferenceSecretSpec `protobuf:"bytes,5,opt,name=spec,proto3" json:"spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceSecret) Reset() {
	*x = InferenceSecret{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceSecret) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceSecret) ProtoMessage() {}

func (x *InferenceSecret) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceSecret.ProtoReflect.Descriptor instead.
func (*InferenceSecret) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{3}
}

func (x *InferenceSecret) GetKind() string {
	if x != nil {
		return x.Kind
	}
	return ""
}

func (x *InferenceSecret) GetSubKind() string {
	if x != nil {
		return x.SubKind
	}
	return ""
}

func (x *InferenceSecret) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *InferenceSecret) GetMetadata() *v1.Metadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferenceSecret) GetSpec() *InferenceSecretSpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

// InferenceSecretSpec defines the secret value for the inference model.
type InferenceSecretSpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Value is the secret value, such as an API key.
	Value         string `protobuf:"bytes,1,opt,name=value,proto3" json:"value,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferenceSecretSpec) Reset() {
	*x = InferenceSecretSpec{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferenceSecretSpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferenceSecretSpec) ProtoMessage() {}

func (x *InferenceSecretSpec) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferenceSecretSpec.ProtoReflect.Descriptor instead.
func (*InferenceSecretSpec) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{4}
}

func (x *InferenceSecretSpec) GetValue() string {
	if x != nil {
		return x.Value
	}
	return ""
}

// InferencePolicy resource maps sessions to summarization models.
type InferencePolicy struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Kind is the resource kind. Should always be set to "inference_policy".
	Kind string `protobuf:"bytes,1,opt,name=kind,proto3" json:"kind,omitempty"`
	// SubKind is the resource sub-kind. Should be empty.
	SubKind string `protobuf:"bytes,2,opt,name=sub_kind,json=subKind,proto3" json:"sub_kind,omitempty"`
	// Version is the resource version. Should be set to "v1".
	Version       string               `protobuf:"bytes,3,opt,name=version,proto3" json:"version,omitempty"`
	Metadata      *v1.Metadata         `protobuf:"bytes,4,opt,name=metadata,proto3" json:"metadata,omitempty"`
	Spec          *InferencePolicySpec `protobuf:"bytes,5,opt,name=spec,proto3" json:"spec,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferencePolicy) Reset() {
	*x = InferencePolicy{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferencePolicy) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferencePolicy) ProtoMessage() {}

func (x *InferencePolicy) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferencePolicy.ProtoReflect.Descriptor instead.
func (*InferencePolicy) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{5}
}

func (x *InferencePolicy) GetKind() string {
	if x != nil {
		return x.Kind
	}
	return ""
}

func (x *InferencePolicy) GetSubKind() string {
	if x != nil {
		return x.SubKind
	}
	return ""
}

func (x *InferencePolicy) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

func (x *InferencePolicy) GetMetadata() *v1.Metadata {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *InferencePolicy) GetSpec() *InferencePolicySpec {
	if x != nil {
		return x.Spec
	}
	return nil
}

// InferencePolicySpec maps sessions to summarization models using a filter.
type InferencePolicySpec struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Kinds are session kinds matched by this policy, e.g., "ssh", "k8s", "db"
	Kinds []string `protobuf:"bytes,1,rep,name=kinds,proto3" json:"kinds,omitempty"`
	// Model is the name of the `InferenceModel` resource to be used for
	// summarization.
	Model string `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	// Filter is an optional filter expression using Teleport Predicate Language
	// to select sessions for summarization. If it's empty, all sessions that
	// match the list of kinds will be summarized using this model.
	Filter        string `protobuf:"bytes,3,opt,name=filter,proto3" json:"filter,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *InferencePolicySpec) Reset() {
	*x = InferencePolicySpec{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *InferencePolicySpec) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*InferencePolicySpec) ProtoMessage() {}

func (x *InferencePolicySpec) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use InferencePolicySpec.ProtoReflect.Descriptor instead.
func (*InferencePolicySpec) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{6}
}

func (x *InferencePolicySpec) GetKinds() []string {
	if x != nil {
		return x.Kinds
	}
	return nil
}

func (x *InferencePolicySpec) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *InferencePolicySpec) GetFilter() string {
	if x != nil {
		return x.Filter
	}
	return ""
}

// Summary represents a summary of a session recording. This format is used to
// store the summaries in the session storage and return it with gRPC.
type Summary struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// sessionId is an ID of the session whose recording got summarized.
	SessionId string `protobuf:"bytes,1,opt,name=session_id,json=sessionId,proto3" json:"session_id,omitempty"`
	// State is the state of the summarization process.
	State SummaryState `protobuf:"varint,2,opt,name=state,proto3,enum=teleport.summarizer.v1.SummaryState" json:"state,omitempty"`
	// InferenceStartedAt is the time when the summarization process started.
	InferenceStartedAt *timestamppb.Timestamp `protobuf:"bytes,3,opt,name=inference_started_at,json=inferenceStartedAt,proto3" json:"inference_started_at,omitempty"`
	// InferenceFinishedAt is the time when the summarization process finished.
	InferenceFinishedAt *timestamppb.Timestamp `protobuf:"bytes,4,opt,name=inference_finished_at,json=inferenceFinishedAt,proto3" json:"inference_finished_at,omitempty"`
	// Content is the main text content of the summary, stored in Markdown
	// format. Available if the state is SUMMARY_STATE_SUCCESS.
	Content string `protobuf:"bytes,5,opt,name=content,proto3" json:"content,omitempty"`
	// ModelName is the name of the `InferenceModel` resource that was used to
	// generate this summary.
	ModelName string `protobuf:"bytes,6,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	// SessionEndEvent is the event that ended the summarized session. Session
	// end events carry the most complete set of data that Teleport has about a
	// given session. Used for checking access based on RBAC rule "where"
	// filters.
	//
	// The event is stored in an unstructured form, as storing an instance of
	// events.OneOf posed a number of technical challenges with JSON
	// serialization as a subcomponent of this message. These challenges stem
	// from the fact that audit events have gogoproto extensions.
	SessionEndEvent *structpb.Struct `protobuf:"bytes,7,opt,name=session_end_event,json=sessionEndEvent,proto3" json:"session_end_event,omitempty"`
	// ErrorMessage is an error message if the summarization failed. Available if
	// the state is SUMMARY_STATE_ERROR.
	ErrorMessage  string `protobuf:"bytes,8,opt,name=error_message,json=errorMessage,proto3" json:"error_message,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Summary) Reset() {
	*x = Summary{}
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Summary) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Summary) ProtoMessage() {}

func (x *Summary) ProtoReflect() protoreflect.Message {
	mi := &file_teleport_summarizer_v1_summarizer_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Summary.ProtoReflect.Descriptor instead.
func (*Summary) Descriptor() ([]byte, []int) {
	return file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP(), []int{7}
}

func (x *Summary) GetSessionId() string {
	if x != nil {
		return x.SessionId
	}
	return ""
}

func (x *Summary) GetState() SummaryState {
	if x != nil {
		return x.State
	}
	return SummaryState_SUMMARY_STATE_UNSPECIFIED
}

func (x *Summary) GetInferenceStartedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.InferenceStartedAt
	}
	return nil
}

func (x *Summary) GetInferenceFinishedAt() *timestamppb.Timestamp {
	if x != nil {
		return x.InferenceFinishedAt
	}
	return nil
}

func (x *Summary) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *Summary) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *Summary) GetSessionEndEvent() *structpb.Struct {
	if x != nil {
		return x.SessionEndEvent
	}
	return nil
}

func (x *Summary) GetErrorMessage() string {
	if x != nil {
		return x.ErrorMessage
	}
	return ""
}

var File_teleport_summarizer_v1_summarizer_proto protoreflect.FileDescriptor

const file_teleport_summarizer_v1_summarizer_proto_rawDesc = "" +
	"\n" +
	"'teleport/summarizer/v1/summarizer.proto\x12\x16teleport.summarizer.v1\x1a\x1cgoogle/protobuf/struct.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!teleport/header/v1/metadata.proto\"\xd3\x01\n" +
	"\x0eInferenceModel\x12\x12\n" +
	"\x04kind\x18\x01 \x01(\tR\x04kind\x12\x19\n" +
	"\bsub_kind\x18\x02 \x01(\tR\asubKind\x12\x18\n" +
	"\aversion\x18\x03 \x01(\tR\aversion\x128\n" +
	"\bmetadata\x18\x04 \x01(\v2\x1c.teleport.header.v1.MetadataR\bmetadata\x12>\n" +
	"\x04spec\x18\x05 \x01(\v2*.teleport.summarizer.v1.InferenceModelSpecR\x04spec\"b\n" +
	"\x12InferenceModelSpec\x12@\n" +
	"\x06openai\x18\x01 \x01(\v2&.teleport.summarizer.v1.OpenAIProviderH\x00R\x06openaiB\n" +
	"\n" +
	"\bprovider\"\xa2\x01\n" +
	"\x0eOpenAIProvider\x12&\n" +
	"\x0fopenai_model_id\x18\x01 \x01(\tR\ropenaiModelId\x12 \n" +
	"\vtemperature\x18\x02 \x01(\x01R\vtemperature\x12+\n" +
	"\x12api_key_secret_ref\x18\x03 \x01(\tR\x0fapiKeySecretRef\x12\x19\n" +
	"\bbase_url\x18\x04 \x01(\tR\abaseUrl\"\xd5\x01\n" +
	"\x0fInferenceSecret\x12\x12\n" +
	"\x04kind\x18\x01 \x01(\tR\x04kind\x12\x19\n" +
	"\bsub_kind\x18\x02 \x01(\tR\asubKind\x12\x18\n" +
	"\aversion\x18\x03 \x01(\tR\aversion\x128\n" +
	"\bmetadata\x18\x04 \x01(\v2\x1c.teleport.header.v1.MetadataR\bmetadata\x12?\n" +
	"\x04spec\x18\x05 \x01(\v2+.teleport.summarizer.v1.InferenceSecretSpecR\x04spec\"+\n" +
	"\x13InferenceSecretSpec\x12\x14\n" +
	"\x05value\x18\x01 \x01(\tR\x05value\"\xd5\x01\n" +
	"\x0fInferencePolicy\x12\x12\n" +
	"\x04kind\x18\x01 \x01(\tR\x04kind\x12\x19\n" +
	"\bsub_kind\x18\x02 \x01(\tR\asubKind\x12\x18\n" +
	"\aversion\x18\x03 \x01(\tR\aversion\x128\n" +
	"\bmetadata\x18\x04 \x01(\v2\x1c.teleport.header.v1.MetadataR\bmetadata\x12?\n" +
	"\x04spec\x18\x05 \x01(\v2+.teleport.summarizer.v1.InferencePolicySpecR\x04spec\"Y\n" +
	"\x13InferencePolicySpec\x12\x14\n" +
	"\x05kinds\x18\x01 \x03(\tR\x05kinds\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12\x16\n" +
	"\x06filter\x18\x03 \x01(\tR\x06filter\"\xa5\x03\n" +
	"\aSummary\x12\x1d\n" +
	"\n" +
	"session_id\x18\x01 \x01(\tR\tsessionId\x12:\n" +
	"\x05state\x18\x02 \x01(\x0e2$.teleport.summarizer.v1.SummaryStateR\x05state\x12L\n" +
	"\x14inference_started_at\x18\x03 \x01(\v2\x1a.google.protobuf.TimestampR\x12inferenceStartedAt\x12N\n" +
	"\x15inference_finished_at\x18\x04 \x01(\v2\x1a.google.protobuf.TimestampR\x13inferenceFinishedAt\x12\x18\n" +
	"\acontent\x18\x05 \x01(\tR\acontent\x12\x1d\n" +
	"\n" +
	"model_name\x18\x06 \x01(\tR\tmodelName\x12C\n" +
	"\x11session_end_event\x18\a \x01(\v2\x17.google.protobuf.StructR\x0fsessionEndEvent\x12#\n" +
	"\rerror_message\x18\b \x01(\tR\ferrorMessage*|\n" +
	"\fSummaryState\x12\x1d\n" +
	"\x19SUMMARY_STATE_UNSPECIFIED\x10\x00\x12\x19\n" +
	"\x15SUMMARY_STATE_PENDING\x10\x01\x12\x19\n" +
	"\x15SUMMARY_STATE_SUCCESS\x10\x02\x12\x17\n" +
	"\x13SUMMARY_STATE_ERROR\x10\x03BXZVgithub.com/gravitational/teleport/api/gen/proto/go/teleport/summarizer/v1;summarizerv1b\x06proto3"

var (
	file_teleport_summarizer_v1_summarizer_proto_rawDescOnce sync.Once
	file_teleport_summarizer_v1_summarizer_proto_rawDescData []byte
)

func file_teleport_summarizer_v1_summarizer_proto_rawDescGZIP() []byte {
	file_teleport_summarizer_v1_summarizer_proto_rawDescOnce.Do(func() {
		file_teleport_summarizer_v1_summarizer_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_teleport_summarizer_v1_summarizer_proto_rawDesc), len(file_teleport_summarizer_v1_summarizer_proto_rawDesc)))
	})
	return file_teleport_summarizer_v1_summarizer_proto_rawDescData
}

var file_teleport_summarizer_v1_summarizer_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_teleport_summarizer_v1_summarizer_proto_msgTypes = make([]protoimpl.MessageInfo, 8)
var file_teleport_summarizer_v1_summarizer_proto_goTypes = []any{
	(SummaryState)(0),             // 0: teleport.summarizer.v1.SummaryState
	(*InferenceModel)(nil),        // 1: teleport.summarizer.v1.InferenceModel
	(*InferenceModelSpec)(nil),    // 2: teleport.summarizer.v1.InferenceModelSpec
	(*OpenAIProvider)(nil),        // 3: teleport.summarizer.v1.OpenAIProvider
	(*InferenceSecret)(nil),       // 4: teleport.summarizer.v1.InferenceSecret
	(*InferenceSecretSpec)(nil),   // 5: teleport.summarizer.v1.InferenceSecretSpec
	(*InferencePolicy)(nil),       // 6: teleport.summarizer.v1.InferencePolicy
	(*InferencePolicySpec)(nil),   // 7: teleport.summarizer.v1.InferencePolicySpec
	(*Summary)(nil),               // 8: teleport.summarizer.v1.Summary
	(*v1.Metadata)(nil),           // 9: teleport.header.v1.Metadata
	(*timestamppb.Timestamp)(nil), // 10: google.protobuf.Timestamp
	(*structpb.Struct)(nil),       // 11: google.protobuf.Struct
}
var file_teleport_summarizer_v1_summarizer_proto_depIdxs = []int32{
	9,  // 0: teleport.summarizer.v1.InferenceModel.metadata:type_name -> teleport.header.v1.Metadata
	2,  // 1: teleport.summarizer.v1.InferenceModel.spec:type_name -> teleport.summarizer.v1.InferenceModelSpec
	3,  // 2: teleport.summarizer.v1.InferenceModelSpec.openai:type_name -> teleport.summarizer.v1.OpenAIProvider
	9,  // 3: teleport.summarizer.v1.InferenceSecret.metadata:type_name -> teleport.header.v1.Metadata
	5,  // 4: teleport.summarizer.v1.InferenceSecret.spec:type_name -> teleport.summarizer.v1.InferenceSecretSpec
	9,  // 5: teleport.summarizer.v1.InferencePolicy.metadata:type_name -> teleport.header.v1.Metadata
	7,  // 6: teleport.summarizer.v1.InferencePolicy.spec:type_name -> teleport.summarizer.v1.InferencePolicySpec
	0,  // 7: teleport.summarizer.v1.Summary.state:type_name -> teleport.summarizer.v1.SummaryState
	10, // 8: teleport.summarizer.v1.Summary.inference_started_at:type_name -> google.protobuf.Timestamp
	10, // 9: teleport.summarizer.v1.Summary.inference_finished_at:type_name -> google.protobuf.Timestamp
	11, // 10: teleport.summarizer.v1.Summary.session_end_event:type_name -> google.protobuf.Struct
	11, // [11:11] is the sub-list for method output_type
	11, // [11:11] is the sub-list for method input_type
	11, // [11:11] is the sub-list for extension type_name
	11, // [11:11] is the sub-list for extension extendee
	0,  // [0:11] is the sub-list for field type_name
}

func init() { file_teleport_summarizer_v1_summarizer_proto_init() }
func file_teleport_summarizer_v1_summarizer_proto_init() {
	if File_teleport_summarizer_v1_summarizer_proto != nil {
		return
	}
	file_teleport_summarizer_v1_summarizer_proto_msgTypes[1].OneofWrappers = []any{
		(*InferenceModelSpec_Openai)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_teleport_summarizer_v1_summarizer_proto_rawDesc), len(file_teleport_summarizer_v1_summarizer_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   8,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_teleport_summarizer_v1_summarizer_proto_goTypes,
		DependencyIndexes: file_teleport_summarizer_v1_summarizer_proto_depIdxs,
		EnumInfos:         file_teleport_summarizer_v1_summarizer_proto_enumTypes,
		MessageInfos:      file_teleport_summarizer_v1_summarizer_proto_msgTypes,
	}.Build()
	File_teleport_summarizer_v1_summarizer_proto = out.File
	file_teleport_summarizer_v1_summarizer_proto_goTypes = nil
	file_teleport_summarizer_v1_summarizer_proto_depIdxs = nil
}
